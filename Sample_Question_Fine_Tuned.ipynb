{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sample Question - Fine Tuned.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLYSrr4_wcIR"
      },
      "source": [
        "Fine Tune example computing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_DOOYiwyVe-",
        "outputId": "8d3d80ea-6d0f-445b-f4e6-794165c7c685"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ht0hha8Ww5jQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fca08678-5dab-45cc-f9ef-00463bcb1cfe"
      },
      "source": [
        "!pip install transformers\n",
        "from transformers import BertTokenizerFast\n",
        "from transformers import AlbertTokenizerFast\n",
        "from transformers import ElectraTokenizerFast\n",
        "import torch\n",
        "path = '/content/gdrive/MyDrive/BERT_tuned_for_SQUAD_2.0_complete'\n",
        "bert_tune = torch.load(path, map_location=torch.device('cpu'))\n",
        "albert_tune = torch.load('/content/gdrive/MyDrive/ALBERT_tuned_for_SQUAD_2.0_complete', map_location = torch.device('cpu'))\n",
        "electra_tune = torch.load('/content/gdrive/MyDrive/ELECTRA_tuned_for_SQUAD_2.0_complete', map_location = torch.device('cpu'))\n",
        "#Tokenizer\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
        "tokenizer_albert = AlbertTokenizerFast.from_pretrained('albert-base-v2')\n",
        "tokenizer_electra = ElectraTokenizerFast.from_pretrained('google/electra-small-discriminator')"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (4.0.1)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLJgghs_l3Br"
      },
      "source": [
        "def normalize_text(s):\n",
        "    \"\"\"Removing articles and punctuation, and standardizing whitespace are all typical text processing steps.\"\"\"\n",
        "    import string, re\n",
        "\n",
        "    def remove_articles(text):\n",
        "        regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n",
        "        return re.sub(regex, \" \", text)\n",
        "\n",
        "    def white_space_fix(text):\n",
        "        return \" \".join(text.split())\n",
        "\n",
        "    def remove_punc(text):\n",
        "        exclude = set(string.punctuation)\n",
        "        return \"\".join(ch for ch in text if ch not in exclude)\n",
        "\n",
        "    def lower(text):\n",
        "        return text.lower()\n",
        "\n",
        "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
        "\n",
        "def compute_exact_match(prediction, truth):\n",
        "    return int(normalize_text(prediction) == normalize_text(truth))\n",
        "\n",
        "def compute_f1(prediction, truth):\n",
        "    pred_tokens = normalize_text(prediction).split()\n",
        "    truth_tokens = normalize_text(truth).split()\n",
        "    \n",
        "    # if either the prediction or the truth is no-answer then f1 = 1 if they agree, 0 otherwise\n",
        "    if len(pred_tokens) == 0 or len(truth_tokens) == 0:\n",
        "        return int(pred_tokens == truth_tokens)\n",
        "    \n",
        "    common_tokens = set(pred_tokens) & set(truth_tokens)\n",
        "    \n",
        "    # if there are no common tokens then f1 = 0\n",
        "    if len(common_tokens) == 0:\n",
        "        return 0\n",
        "    \n",
        "    prec = len(common_tokens) / len(pred_tokens)\n",
        "    rec = len(common_tokens) / len(truth_tokens)\n",
        "    \n",
        "    return 2 * (prec * rec) / (prec + rec)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SO4SQykA1kBX"
      },
      "source": [
        "context = 'Following the Cretaceous–Paleogene extinction event, the extinction of the dinosaurs and the wetter climate may have allowed the tropical rainforest to spread out across the continent. From 66–34 Mya, the rainforest extended as far south as 45°. Climate fluctuations during the last 34 million years have allowed savanna regions to expand into the tropics. During the Oligocene, for example, the rainforest spanned a relatively narrow band. It expanded again during the Middle Miocene, then retracted to a mostly inland formation at the last glacial maximum. However, the rainforest still managed to thrive during these glacial periods, allowing for the survival and evolution of a broad diversity of species.'\n",
        "question = 'Which type of climate may have allowed the rainforest to spread across the continent?'"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbGeOQimAS7w"
      },
      "source": [
        "Bert\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPAyeYEN1puW"
      },
      "source": [
        "def bert_fine_tune(context, question):\n",
        "  answers = []\n",
        "  encoding = tokenizer.encode_plus(text=context,text_pair=question)\n",
        "  inputs = encoding['input_ids']  #Token embeddings\n",
        "  sentence_embedding = encoding['token_type_ids']  #Segment embeddings\n",
        "  tokens = tokenizer.convert_ids_to_tokens(inputs) #input tokens\n",
        "  outputs = bert_tune(input_ids=torch.tensor([inputs]), token_type_ids=torch.tensor([sentence_embedding]))\n",
        "  start_index = torch.argmax(outputs.start_logits)\n",
        "  end_index = torch.argmax(outputs.end_logits)\n",
        "  answer = ' '.join(tokens[start_index:end_index+1])\n",
        "  corrected_answer = ''\n",
        "  for word in answer.split():\n",
        "        \n",
        "        #If it's a subword token\n",
        "      if word[0:2] == '##':\n",
        "          corrected_answer += word[2:]\n",
        "      else:\n",
        "          corrected_answer += ' ' + word\n",
        "  answers.append (corrected_answer)\n",
        "  return answers"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orupRSdn134W",
        "outputId": "d9ae05e6-395c-434e-9b07-38f4fe0be1fb"
      },
      "source": [
        "bert_tune_answer = bert_fine_tune(context, question)\n",
        "bert_tune_answer"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' wetter']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WP8IXNma2JeD"
      },
      "source": [
        "true_answer = ['the wetter climate may have allowed the tropical rainforest to spread out across the continent', 'wetter']"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVRx6HRgCMGA",
        "outputId": "05d3c193-541c-4b4b-e7aa-26e3d5377592"
      },
      "source": [
        "em_score = max((compute_exact_match(bert_tune_answer[0], a) for a in true_answer))\n",
        "f1_score = max((compute_f1(bert_tune_answer[0], a) for a in true_answer))\n",
        "print(em_score)\n",
        "print(f1_score)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XMW6VoHAV-_"
      },
      "source": [
        "Albert\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rs_rW1XpuAmV"
      },
      "source": [
        "def albert_fine_tune(context, question):\n",
        "  answers = []\n",
        "  encoding = tokenizer_albert.encode_plus(text=context,text_pair=question)\n",
        "  inputs = encoding['input_ids']  #Token embeddings\n",
        "  sentence_embedding = encoding['token_type_ids']  #Segment embeddings\n",
        "  tokens = tokenizer_albert.convert_ids_to_tokens(inputs) #input tokens\n",
        "  outputs = albert_tune(input_ids=torch.tensor([inputs]), token_type_ids=torch.tensor([sentence_embedding]))\n",
        "  start_index = torch.argmax(outputs.start_logits)\n",
        "  end_index = torch.argmax(outputs.end_logits)\n",
        "  answer = ' '.join(tokens[start_index:end_index+1])\n",
        "  corrected_answer = ''\n",
        "  for word in answer.split():\n",
        "        \n",
        "        #If it's a subword token\n",
        "      if word[0:2] == '##':\n",
        "          corrected_answer += word[2:]\n",
        "      else:\n",
        "          corrected_answer += ' ' + word\n",
        "  answers.append(corrected_answer)\n",
        "  return answers"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "OBUJaebP_S9d",
        "outputId": "434fed67-3318-4894-cd05-48bc639e0b18"
      },
      "source": [
        "albert_tune_answer = albert_fine_tune(context, question)\n",
        "albert_tune_answer[0]"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' ▁we tter'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1zH1SfLit6E",
        "outputId": "1d9c599a-3b46-42de-ed7e-9ef0c43eaea6"
      },
      "source": [
        "import re\n",
        "import string\n",
        "albert_tune_answer[0] = albert_tune_answer[0].replace(\"▁\", \"\")\n",
        "albert_tune_answer[0] = albert_tune_answer[0].replace(\" \", \"\")\n",
        "albert_tune_answer"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['wetter']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OkfPa_nBtSd",
        "outputId": "e0d6d4d2-c5cd-4611-ca76-bf0b16dd4eda"
      },
      "source": [
        "em_score = max((compute_exact_match(albert_tune_answer[0], a) for a in true_answer))\n",
        "f1_score = max((compute_f1(albert_tune_answer[0], a) for a in true_answer))\n",
        "print(em_score)\n",
        "print(f1_score)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLW7HahhAXwR"
      },
      "source": [
        "Electra"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OugtDZrAQUJ"
      },
      "source": [
        "def electra_fine_tune(context, question):\n",
        "  answers = []\n",
        "  encoding = tokenizer_electra.encode_plus(text=context,text_pair=question)\n",
        "  inputs = encoding['input_ids']  #Token embeddings\n",
        "  sentence_embedding = encoding['token_type_ids']  #Segment embeddings\n",
        "  tokens = tokenizer_electra.convert_ids_to_tokens(inputs) #input tokens\n",
        "  outputs = electra_tune(input_ids=torch.tensor([inputs]), token_type_ids=torch.tensor([sentence_embedding]))\n",
        "  start_index = torch.argmax(outputs.start_logits)\n",
        "  end_index = torch.argmax(outputs.end_logits)\n",
        "  answer = ' '.join(tokens[start_index:end_index+1])\n",
        "  corrected_answer = ''\n",
        "  for word in answer.split():\n",
        "        \n",
        "        #If it's a subword token\n",
        "      if word[0:2] == '##':\n",
        "          corrected_answer += word[2:]\n",
        "      else:\n",
        "          corrected_answer += ' ' + word\n",
        "  answers.append(corrected_answer)\n",
        "  return answers"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXAft5ZPAu2u",
        "outputId": "980940c8-2ca3-4f7e-cdc9-e717f8ce8738"
      },
      "source": [
        "electra_tune_answer = electra_fine_tune(context, question)\n",
        "electra_tune_answer"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' wetter climate']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNw56voVFtrh",
        "outputId": "94c53664-a607-434e-d802-1b579ace47b3"
      },
      "source": [
        "em_score = max((compute_exact_match(electra_tune_answer[0], a) for a in true_answer))\n",
        "f1_score = max((compute_f1(electra_tune_answer[0], a) for a in true_answer))\n",
        "print(em_score)\n",
        "print(f1_score)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "0.6666666666666666\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}